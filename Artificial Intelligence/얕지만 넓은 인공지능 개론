# 주의 !!!
직접 작성하였으므로 잘못된 정보 존재할 수 있음.

차차 수정예정

마지막 수정 : 2024/11/11

-----------------------------------------------

1. 인공지능이란 ?
기존의 규칙기반 프로그램을 넘어, 인간의 신경망을 본따 만든 인공신경망을 통해 스스로 의사결정하고 예측할 수 있는 프로그램

2. 머신러닝이란 ?
모델이 데이터로부터 유의미한 패턴을 추출하고 학습하는 방법을 총체적으로 일컫는 말.

3. 딥러닝이란 ?
인간의 신경망 구조를 본따 만든 인공신경망 개념을 기반으로 데이터의 유의미한 패턴을 추출, 분석, 학습하는 방법.

4. Supervised Learning
지도 학습은 모델이 데이터 뿐만 아니라 데이터의 정답 정보(Label)까지 함께 학습에 사용하는 학습이다.

Classification, Regression 모델들이 일반적으로 지도 학습에 속함.

5. Classification
분류는 새로운 데이터가 들어왔을 때 해당 데이터가 어느 클래스에 속하는지 모델이 예측하는 것을 의미.

두 개의 클래스 사이에서 예측 시 Binary Classification, 다중 클래스 분류 시 Categorical Classification이라 정의함.

대표적인 분류 모델로 Logistic Regression, Support Vector Machine 등이 있다.

6. Logistic Regression
로지스틱 회귀는 이름과 달리 Binary Classification을 수행하는 모델이다.

이름에 회귀가 들어간 이유는 Logit 이라는 값을 Linear Regression 함으로써 분류하기 때문.

Logit은 Log-Odds로, 이길 확률(승산)을 의미하고 q/1-q로 계산함.

이 Log-Odds를 Sigmoid 활성화 함수에 통과시키면  0~1 사이로 정규화되어 출력되는데, Threshold에 따라 0인지 1인지 최종 결정됨.

손실함수로 Binary Cross Entropy Loss를 사용하고, 이를 최적화하는 방향으로 학습을 진행함.

7. Support Vector Machine
서포트 벡터 머신은 Binary Classification을 수행하는 모델이다.

두 클래스를 가장 잘 분리하는 결정 경계와  그 기울기를 찾는 것이 목표이다.

이를 위한 여러 방법이 존재하며 그 중 하나로 라그랑주 승수법 활용 방법에 대해 설명하겠음.

라그랑주 승수법은 라그랑지안 함수 기반 최적화 방법으로, 이를 활용하면 한 번에 최적의 결정 경계를 찾을 수 있다.

L(x,y,lamda) = f(x,y) - lamda*g(x,y)

함수 f는 최적화하려는 함수, g는 제약조건을 의미함.

이를 통해 최적의 결정 경계가 정해지면, 결정 경계와 가장 가까운 두 데이터 포인트를 Support Vector로 선정함.

이후 Support Vector 간의 마진이 최대가 되는 결정 경계의 기울기를 찾도록 학습을 진행함으로써 이진 분류가 가능해진다.

선형적으로 분리할 수 없는 데이터는 Kernel Trick을 통해 고차원 변환하여 분리 가능함.

8. Activation Function
활성화 함수는 입력값을 정규화하거나 비선형성을 부여하는 등 특정 형태로 변환하여 출력값으로 반환해주는 함수임.

실수 값을 입력으로 받아 0~1 사이의 확률값으로 출력하는 Sigmoid Function,

벡터를 입력으로 받아 0~1 사이의 확률값으로 출력하는 Softmax Function,

값을 -1~1로 정규화하여 표현하는 Tanjent Hyperbolic Function,

입력값이 음수이면 0으로, 양수이면 그대로 출력하는 Rectified Linear Unit Function

등이 대표적임.

9. Dying ReLu
모든 입력값이 음수일 시 모든 출력값이 0이 되어 버리는 현상을 의미함. 발생 시 가중치 업데이트가 전혀 이루어지지 않음.

음수를 0이 아닌 값으로 출력할 필요가 있으며, 이에 Exponential ReLU, Leaky ReLU, Gaussian Error Linear Unit 등의 개선된 함수가 제안됨.

10. Exponential Rectified Linear Unit
음수 값에 Exponential 연산 함으로써 부드러운 음수 처리를 가능케 함. 양수 처리는 ReLU와 동일.

11. Leaky Rectified Linear Unit
아주 작은 음수(0.01 등)는 허용하여, 학습이 아예 멈추는 경우를 방지함. 가장 일반적으로 사용됨.

12. Cross Entropy Loss
실제 Label값과 모델이 예측한 값 사이의 오차를 정의하는 손실 함수 중 하나로,

Cross Entropy Loss는 Label의 확률분포와 예측값의 확률분포 차이를 계산하도록 정의되었다.

이진 분류에서는 Binary Cross Entropy Loss, 다중 분류에서는 Categorical Cross Entropy Loss라고 명명함.

13. Regression
회귀는 독립변수 x를 입력값으로 주어 종속변수 y값을 예측하는 것을 의미함.

결과가 선형으로 나타날 시 Linear Regression, 나아가 선형 직선일 시 Simple Linear Regression, 평면일 시 Multiple Linear Regression이라 표현함.

비선형으로 나타나면 Non-Linear Regression임.

14. K-Neariest Neighborhood
K-최근접 이웃 알고리즘은 지도 학습 알고리즘에 속하는 거리 기반 Classification 모델임

'유사한 특징을 가진 데이터들은 같은 그룹에 속할 것이다'라는 것이 핵심 이론으로,

새로운 데이터가 들어오면 해당 데이터를 가장 가까이에 위치한 K개의 이웃 데이터가 속한 그룹에 배치함으로써 분류를 수행함.

15. Unsupervised Learning
비지도 학습은 정답 정보인 Label 없이 데이터만으로 학습하는 학습 방법이다.

비지도 학습 모델은 사용자가 제공한 데이터셋으로부터 유의미한 패턴들을 추출하고 학습하여 객체에 대한 정보를 스스로 정의해 나간다.

Clustering이 대표적임.

16. Clustering
군집화는 대표적인 비지도 학습 기법으로, 유사한 패턴의 데이터들을 같은 그룹으로 묶어 학습하는 기법을 의미함.

17. K-Means Clustering
K-평균 군집화는 심화된 Clustering 기법임.

유사한 패턴의 데이터를 찾아 K개의 그룹으로 군집화하고, 각 그룹의 중심에 Centroid를 할당한 뒤 그룹 내 데이터들이 Centroid에 수렴하도록, 각 그룹은 잘 분리되도록 학습한다.

군집화 정도를 판단하기 위한 지표로 0~1 사이의 값으로 나타나는 Silhouette Coefficient를 사용하며, 1에 가까울수록 그룹 내 데이터들이 잘 수렴하고 각 그룹은 잘 분리되었음을 의미함.

19. Semi-Supervised Learning
준지도학습은 Labelling된 데이터와 그렇지 않은 데이터를 함께 학습에 사용하는 기법이다.

Labelling된 데이터의 수가 상대적으로 적을 때 주로 사용하며,

Labelling된 데이터를 우선 학습하고, 이를 기반으로 Labelling되지 않은 데이터에 Pseudo Labelling함으로써 학습함.

20. Reinforcement Learning
강화 학습은 행동하는 주체 Agent와 상호작용하는 Environment로 구성되어, Agent가 Environment 내에서 최적의 보상을 얻을 수 있는 최적의 행동을 스스로 찾아 나가는 학습 방법임. 

Agent가 특정 상태에서 취할 수 있는 행동을 정의하는 함수를 Policy Function,

Agent가 특정 상태에서 특정 행동을 취함으로써 받는 보상을 정의하는 함수를 Reward Function 또는 Value Function이라 함.

세부적인 지침에 따라 On, Off Policy Learnig이나 Model-Based, Free Learning 등으로 구분할 수 있음.

21. On-Policy Learning
행동하는 Agent와 학습하는 Agent가 같은 경우를 의미함. Agent가 직접 행동하면서 보상을 탐색하는 기본적인 알고리즘임.

22. Off-Policy Learning
행동하는 Agent와 학습하는 Agent가 분리되어 있는 경우임. 행동 Agent는 기존에 알려진 최적의 행동을 수행하며, 학습 Agent는 새로운 보상을 찾아 Exploration함. 

Q-Learning이 대표적인 Off-Policy임.

23. Q-Learning
Agent가 특정 State에서 특정 행동을 취함으로써 얻을 수 있는 보상의 기댓값을 Q값이라 정의하고, 이 Q값을 모든 상황에서 최대화하도록 학습 진행하는 것을 의미한다.

Q값을 Q Table에 저장하며 최대의 보상을 기억하고, 모든 값을 저장하기에 경우의 수가 너무 많을 시 Function Approximation으로 보상의 근사값을 구하여 저장하기도 한다.

Explorarion-Exploitation Tradeoff이 존재하므로 둘 사이의 적절한 균형을 맞춰주는 것이 중요한데, Epsilon-Greedy 알고리즘을 활용하여 일부는 Exploration하고 일부는 Exploitation하게 설정할 수 있다.

24. Model-Based Learning
Agent가 환경에 대한 명시적인 정보가 담긴 Model을 제공받아 학습하는 것을 의미함.

Agent는 직접 행동해보지 않아도 어떤 행동으로 어떤 보상을 얻을 수 있는지 예측 가능함. 이를 통해 향후 방향성을 계획하는 Planning을 수행하는 것이 핵심 아이디어임.

Dynamic Programming 기반으로 구현 가능하다.

환경이 너무 거대한 경우에는 적합하지 않음.

25. Model-Free Learning
환경에 대한 정보 없이, 즉 환경 모델 없이 학습하는 것을 의미함.

Agent는 직접 환경과 상호작용 및 행동해가며 더 나은 보상을 찾아내 가야 함.

Q-Learning이 이에 속함.

26. Discount Factor
할인율은 강화 학습의 중요한 개념 중 하나로, 미래의 가치를 현재의 가치에 얼마나 반영할지 결정하는 변수임.

할인율이 높으면 미래의 가치를 중요시 여기므로 Exploration에 초점을 두게 됨.

할인율이 낮을 시 미래의 가치보다 현재의 가치를 중시하므로 Exploitation에 초점을 둠.

적절한 값을 설정하는 것이 중요함.

27. Multi-Armed Bandit
슬롯머신이 있고, 슬롯머신 내 각 슬롯의 확률이 모두 다르다고 가정하였을 때, 모든 슬롯에서 최고의 보상을 얻도록 학습하는 강화학습 알고리즘.

27. Curse Of Dimension
차원의 저주란 입력 데이터의 특징이 많아질수록 모델이 데이터 간의 유의미한 패턴을 추출, 학습하지 못하는 현상을 의미한다. 

예를 들어, 100*100 크기 그레이스케일 이미지의 모든 픽셀을 특징으로 사용할 시 10,000개의 특징을 사용하는 것이므로 연산량이 과도해지고 패턴 학습이 불가할 것이다.

해결을 위해 SVD, PCA 사용 가능.

28. Singular Value Decomposition
특이값 분해는 모든 행렬을 3개의 행렬로 분해할수 있다는 이론에 의거하여 입력 행렬을 3개의 출력 행렬로 분해하는 방법이다.

왼쪽 직교 행렬과 대각행렬, 오른쪽 직교 행렬로 분해하며 각 행렬은 기저벡터, 특이값, 열공간 정보를 담는다.

29. Principal Component Analysis
주성분 분석은 학습 과정에서의 불필요한 연산을 줄이고, 차원의 저주를 방지하기 위한 차원 축소 방법이다.

데이터의 분산을 가장 잘 나타내는 N개의 주성분을 기준으로 불필요한 차원을 제거하는데, 세부적인 과정은 다음과 같다.

a) 입력 데이터에 대한 공분산 행렬을 구한다.
b) 해당 공분산 행렬에 SVD하여 특이값 행렬을 구한다.
c) 특이값 행렬로부터 Eigenvector, Eigenvalue를 구한다.
d) Eigenvalue가 가장 큰 상위 N개의 Eigenvector를 Principal Component로 선정한다.
e) Principal Component가 데이터의 분산을 가장 잘 설명하는 핵심 데이터이므로 나머지 차원은 축소한다.

여기서 Eigenvector는 어떤 벡터를 가진 행렬을 확장(선형 변환)하여도 방향이 변하지 않는 벡터를 의미하며, Eigenvalue는 그 때 변한 크기를 의미함.

30. Gradient Vanishing
기울기 소실은 딥러닝 네트워크가 깊어질수록 Backpropagation이 많이 수행되며 가중치의 업데이트량이 0에 수렴하는 현상을 의미한다. 

Backpropagation 자체가 원인은 아니고, 정확히는 Backpropagation을 거듭할수록 특정 활성화 함수를 많이 통과하기 때문이다. 

미분할때마다 값이 작아지는 Sigmoid, TanH 등 활성화 함수를 통과 -> 역전파 -> 통과 -> 역전파 ... 를 반복하며 해당 현상이 발생하게 된다.

31. Gradient Exploding
기울기 폭주는 Backpropagation을 거듭하며 가중치에 곱셈 연산이 여러번 이루어져 특정 가중치의 값이 과도하게 커지는 현상을 의미한다.

Gradient Clipping으로 가중치의 크기를 제한하여 방지할 수 있다.

32. Backpropagation
역전파는 출력 방향에서 입력 방향, 즉 역방향으로 Loss를 전파하는 것을 의미함.

Loss의 크기에 따라 다음 가중치 업데이트량을 조절하기 위해 사용한다.

33. Variational AutoEncoder
Variational AutoEncoder는 데이터를 생성하는 모델로, 인코더와 디코더로 구성된 아키텍쳐임. 

인코더는 입력 데이터의 핵심 특징을 요약하여 Latent Space(잠재 공간)에 표현하고, 디코더는 잠재 공간의 핵심 특징만 가지고 원본 데이터를 복구하는 행위를 반복하며 학습함.

다양한 패턴의 데이터를 생성할 수 있지만 품질이 낮을 수 있음.

34. Latent Space
잠재 공간은 데이터의 핵심적인 특징만 압축하여 표현해둔 공간을 의미한다.

35. GAN
Generative Adversarial Network(생성적 적대 신경망)은 데이터를 생성하는 모델로, 생성자와 판별자가 경쟁적으로 학습하는 모델임.

생성자는 랜덤한 노이즈로부터 실제와 유사한 데이터를 생성하고, 판별자는 생성자가 만든 데이터가 진짜인지 가짜인지 구별함. 생성자는 판별자를 속이기 위해 점점 더 실제같은 데이터를 생성하고, 판별자는 해당 데이터를 점점 정교하게 구분해나감.

결과적으로 GAN은 실제와 아주 유사한 데이터를 생성할 수 있음.

그러나 특정 패턴의 데이터 생성만 잘하게 되어 버리는 Mode Collapse 현상이 발생할 수 있다.

36. Attention Mechanism
어텐션 메커니즘은 모델이 데이터의 중요한 부분에 집중하게 해 주는 것임.

예를 들어, 기계 번역 시 문장을 통으로 처리하기 보단, 현재 주어진 단어와 관련된 단어에 더 집중함으로써 번역의 정확도를 향상시킴.

본래 RNN에서 사용이 되었지만, RNN 특성 상 흐려지는 정보에 집중해 버리는 문제가 발생하여 현재는 발전된 형태인 Self-Attention을 사용함. 관련된 데이터 뿐만 아니라 자기 자신에도 집중하여 정보가 흐려지지 않게 하는 것임. Self Attention은 현재 Transformer 모델에 활발히 사용됨.

37. Transfer Learning
전이 학습은 이전에 학습된 모델의 가중치를 불러와 새로운 학습에 적용하는 것임.

예를 들어, AI Hub의 대규모 이미지셋으로 학습시킨 모델을 다운받아, 내가 원하는 소규모 데이터셋에 추가 학습 시킴으로써 미세 조정하는 Fine Tuning은 전이 학습에 속함.

38. Convolution Neural Network
CNN은 공간적, 지역적 정보 추출에 특화된 알고리즘으로 이미지 처리에 주로 사용된다.
필자가 캡스톤디자인 프로젝트에 사용된 YOLOv7이 CNN 기반 모델임.

Convolution Layer, Pooling Layer로 구성되며 Flatten, Stride, Padding 연산 등이 존재함.

39. Convolution Layer
합성곱 계층은 Convolution 연산을 수행하는 계층이다.

Filter(또는 Kernel)라는 작은 크기의 행렬을 이미지 위에 슬라이딩 시키며 이미지가 가지는 주요 특징들을 Feature Map으로 매핑한다.

40. Pooling Layer
풀링 계층은 Convolution을 통해 만들어진 Feature Map의 크기를 Max Pooling, Average Pooling 연산하여 줄이는 역할을 수행한다.

두 Pooling은 특징 맵의 일정 지역을 구성하는 사각행렬의 값을 Max 연산하거나, Average 연산함으로써 축소시킨다.

중요한 정보를 더 잘 유지하는 Max Pooling이 주로 사용된다.

41. Flatten
평탄화는 행렬 내의 값을 Weight에 곱하기 수월하도록 열벡터로 펼쳐주는 연산.

42. Padding
Convolution 연산 시 Filter가 이미지의 가장자리보다 중심부를 더 많이 슬라이딩 하는 현상이 발생. 따라서 가장자리의 특징이 중심에 비해 잘 추출되지 않음.

이에 이미지의 가장자리에 0이라는 값을 한 칸씩 더 붙여줌으로써 Filter가 가장자리도 여러번 슬라이딩할 수 있도록 해주는 연산이 패딩 연산임.

패딩 연산 시 입력 행렬과 출력 행렬의 크기가 동일해지는 효과가 있음.

43. Recurrent Neural Network
RNN은 시계열 데이터, 즉 연속적인 데이터 처리에 특화된 통계 기반 수치 해석 모델이다.

입력과 출력을 시퀀스 단위로 처리하는 시퀀스 모델이기도 하다.

장기 시퀀스를 처리하는 과정에서 과거의 정보를 점차 잊어버리는 의존성 소실 문제가 존재, 따라서 이를 보완한 LSTM이나 GRU 아키텍쳐가 제안되었다.

44. Long-Short Term Memory
LSTM은 앞서 서술한 RNN의 장기 의존성 소실 문제를 극복하기 위해 제안된 아키텍쳐이다. 

기억 셀, 입력 게이트, 출력 게이트, 망각 게이트로 구성되어 기억 셀로 중요한 정보는 따로 흐르게 하여 기억하고, 망각 게이트에서 중요하지 않은 정보들을 제거하는 방식으로 문제를 해결함.

45. Gated Recurrent Unit
GRU는 LSTM 이후에 제안된 아키텍쳐로, 업데이트 게이트와 리셋 게이트로 구성되어 RNN의 장기 의존성 소실 문제를 해결하였다.

업데이트 게이트는 LSTM의 입력 게이트와 기억 셀의 역할을 하여 새로운 정보를 얼마나 받아들이고 중요한 정보를 얼마나 유지할 지 결정, 리셋 게이트는 출력, 망각 게이트의 역할을 하여 중요하지 않은 정보를 얼마나 잊어버릴 지 결정한다.

46. Hyperparameter
하이퍼파라미터는 학습을 위해 사용자가 직접 설정하는 값으로 Epoch, Batch Size 등이 이에 해당한다.

47. Epoch
학습을 위해 데이터셋 순회를 몇 회 반복할지 학습할지 결정하는 Hyperparameter.

48. Batch Size
배치 크기는 학습 시 한번에 몇 개의 데이터를 묶어 처리할 것인지 결정하는 Hyperparameter임.

Batch Size가 클 수록 여러 개의 데이터를 묶어 한번에 처리하므로 빠른 학습이 가능하지만, 그만큼 메모리 사용량이 높다.

Batch Size가 작으면 연산량이 높아져 학습이 오래 걸리지만, 메모리 사용량이 낮다.

2의 배수로 설정하는 것이 메모리 운용에 효율적임.

48. Grid Search
최적의 하이퍼파라미터 조합을 탐색하는 기법이며, Grid Search는 하이퍼파라미터의 모든 조합을 시도한다. 따라서 하이퍼파라미터의 종류가 많아질수록 연산량이 대폭 증가한다.

50. Random Search
하이퍼파라미터의 랜덤한 일부 조합만 시도하여 그 중 가장 좋은 조합을 선정한다.
국소 최적해에 빠질 가능성이 크다.

51. Parameter
하이퍼파라미터와 달리 학습 과정에서 모델이 동적으로 변경시켜나가는 값을 의미한다. Weight, Loss 등이 이에 해당한다.

52. Weight
가중치란 모델의 학습 과정에서 특정 요인에 얼마나 영향받을지를 결정하는 변수이다.

53. Learning Rate
모델의 손실함수를 최적화하는 과정에서 가중치 업데이트가 한번에 어느 정도 이루어질지 결정하는 변수이다. 학습률이 너무 크면 최적해를 지나쳐 발산할 수 있고, 학습률이 너무 작으면 업데이트 속도가 느려 좀처럼 최적해에 도달하지 못할 수 있다.

54. Loss
손실함수는 모델이 예측한 값과 실제 Label 값의 차이를 어떤 방식으로 정의할지 결정하는 함수를 의미한다.

대표적인 손실함수로 L1 Loss, L2 Loss, Cross Entropy Loss 등이 있다.

55. L1 Loss
예측값과 정답값의 차이를 Mean Absolute Error로 정의한 것.

1/N Sigma(i=1~N) |Ypredict - Ytrue|로 계산함.

56. L2 Loss
예측값과 정답값의 차이를 Mean Sqaured Error(잔차제곱평균)으로 정의한 것.

1/N Sigma(i=1~N) (Ypred-Ytrue)^2으로 계산함.

57. EXplainable Artificial Intelligence
XAI는 설명 가능한 인공지능이라 표현하고,  어떠한 예측을 수행하였을 때 해당 예측에 대한 근거를 설명할 수 있는 AI를 의미함.

예를 들어, AI가 어떤 인간의 미래 범죄율을 100%라 예측했다고 가정하자. 그러나 예측의 근거를 설명할 수 없다면 해당 예측은 사회적으로 아무 효력 없는 예측이나 다름없다.

예측이 어떤 요인에 얼마나 영향 받았는지 인간이 해석 가능하도록 하면 됨.

58. Overfitting
과적합은 학습 과정에서 발생하는 현상으로, 모델이 학습 데이터에 너무 적응하여 실제 데이터를 오히려 잘 예측하지 못하는 경우를 의미한다.

모델의 Complexity가 높다고도, Bias가 낮다고도, Generalization Ability가 낮다고도 표현한다.

Cross-Validation하여 Train Data와 Test Data의 Loss를 동시에 추적하면 과적합 시점 판단 가능함.

Train Data에 대한 Loss가 감소하는데, Test Data에 대한 Loss는 감소하지 않거나 증가한다면 그 시점으로부터 과적합으로 판단함.

Early-Stopping, Dropout, Regularizarion, Batch Normalization, Data Augmentation 등 여러 해결 방법이 존재함.

59. Model Complexity
모델이 얼마나 복잡한지를 의미함. 적당한 복잡도가 좋은 모델이다.

너무 복잡하면 그 복잡함으로 인해 오히려 예측을 잘 수행하지 못하며, 너무 단순해도 데이터의 패턴을 이해하지 못함.

60. Bias
편향은 모델이 얼마나 단순하여 복잡한 패턴을 학습하지 못하는가를 의미한다. 즉 편향이 높으면 모델이 너무 단순해 복잡한 패턴의 학습이 어려워진다.

61. Variance
수학적으로 분산은 데이터의 퍼짐 정도를 의미하지만, 인공지능에서는 모델이 데이터의 국소적 특징에 얼마나 민감하게 반응하는지를 의미함.

즉 분산이 높으면 모델이 너무 작은 특징에도 민감하게 반응하여 복잡성이 과도하게 높아질 수 있음.

62. Bias-Variance Tradeoff
편향과 분산은 트레이드오프 관계에 있기 때문에, 편향이 높아지면 분산은 낮아지고 편향이 낮아지면 분산은 높아진다. 즉 적절한 관계를 유지해야 함.

달리 설명하자면,

편향이 높아 모델이 너무 단순하면 데이터의 국소적 특징을 전혀 추출하지 못하고,

편향이 낮아 모델이 너무 복잡하면 데이터의 국소적 특징에 전부 반응하여 과적합된 모델이 된다.

63. Generalization Ability
일반화 능력은 모델이 학습 데이터 뿐만 아니라 실제 데이터에 대한 예측도 얼마나 잘 수행하는지를 의미함.

64. Cross Validation
Train Data의 일부를 Test Data로 사용하여 두 Data에 대한 Loss를 동시에 추적하는 것.

65. K-Fold Cross Validation
Train Data를 K개의 서브셋으로 분할하고, 각 서브셋들을 모두 Test Data로 한번씩 사용하여 교차 검증하는 기법.

66. Dropout
드롭아웃은 Overfitting 방지 기법으로, 학습 과정에서 모델의 일부 뉴런을 랜덤하게 비활성화시켜 모델이 특정 뉴런에 과도하게 의존하는 것을 방지함.

67. Early-Stopping
조기 종료는 Overfitting 방지 기법으로, 사용자가 설정한 Epoch를 모두 완료하지 않았더라도 모델의 성능이 개선되지 않는 것으로 판단되면 조기에 학습을 종료시킴.

Cross-Validation하여 Train Data와 Test Data에 대한 Loss를 동시 추적하여, Train Data에 대한 Loss가 감소하지만 Test Data에 대한 Loss는 감소하지 않거나 증가한다면 그 시점이 과적합 시작 시점이므로 그 때 학습을 종료하도록 설정하면 됨.

68. Regularization
정규화는 수학적으로 값을 일정 범위로 치환해주는 행위를 뜻하지만, 인공지능에서는 손실함수에 가중치의 크기를 함께 고려하여 모델의 성능을 개선시키는 기법을 의미한다.

L1, L2 Regularization이 있으며 각각 L1, L2 Loss을 사용한다.

L1(Lasso) 정규화는 L1 Loss에 패널티를 부여하여 모델의 성능에 도움이 되지 않는 일부 가중치를 0으로 만든다. 즉 필요 없는 가중치를 죽여 모델을 경량화시키는 것임.
Outlier를 고려하지 않아도 될 때 사용함.

L2(Ridge) 정규화는 L2 Loss에 패널티를 부여하여 너무 큰 가중치의 값을 줄이는 것. Outlier를 고려해야 할 때 사용함.

69. Batch Normalization
모델의 일반화 성능을 높이기 위한 기법으로 각 미니배치가 받는 입력 데이터를 표준화함.

다르게 표현하면, 레이어들이 받는 입력 데이터들의 분포를 균등하게 함으로써 Internal Covariance Shift(내부 공변량 변화)를 줄인다고도 함.

이를 위해 입력 데이터들의 평균을 0, 분산을 1로 만드는 표준정규분포화(표준화) 연산을 적용, 이후 스케일링과 시프트 연산을 수행함.

70. Data Augmentation
데이터 오버샘플링이라고도 하며, 데이터의 양을 늘리기 위해 기존 데이터셋을 복제하고, 복제된 데이터에 Masking, Resizing, Rotation을 수행하는 것임.

-----

71. Underfitting
미적합, 과소적합이라고도 표현하며 모델의 편향이 높아 실제 데이터 뿐만 아니라 학습 데이터마저 잘 예측하지 못하는 현상을 의미함.

단순히 Epoch 수를 늘려주는 것만으로도 해결 가능한 경우가 많음.

72. Data Imbalance
데이터 불균형은 특정 클래스 데이터의 수에 비해 다른 클래스 데이터의 수가 너무 적은 경우를 의미함.

많은 쪽의 데이터를 언더샘플링(삭제)하거나, 적은 쪽의 데이터를 오버샘플링하여 해결 가능함.

또한 적은 쪽의 데이터에 가중치가 큰 영향을 받도록 조정하여 해결할 수도 있음.

73. Decision Tree
의사결정 나무는 데이터들을 계층형 구조인 Tree 형태로 배치하고, 특정 판단 기준에 의거하여 Leaf Node에 도달할때까지 예측을 반복하며 최종 예측 결과를 도출하는 알고리즘임.

데이터를 배치하는 기준은 Gini Impurity와 Entropy.

74. Gini Impurity
지니 불순도는 여러 개의 클래스 데이터들이 얼마나 섞여 있는지를 의미함. 

0~1의 값으로 나타나며,
1-Sigma(i=1~C)Pi로 계산할 수 있다.

75. Entropy
엔트로피는 더 나아가, 여러 개의 클래스가 섞임으로 인해 예측이 얼마나 어려운지를 의미한다. 

정보의 불확실성이라고도 하며,
-Sigma(i=1~C)Pi Log2 Pi로 계산한다.

76. Random Forest
랜덤 포레스트는 여러 개의 Decision Tree를 Bagging으로 묶어 단일 Decision Tree가 가지는 Overfitting 위험이나 예측력 부족을 극복한 알고리즘임.

여러 개의 Decision Tree가 예측해낸 결과를 평균내거나 투표하여 최종 예측함.

77. Ensemble Learning
앙상블 학습은 여러 모델을 결합하여 학습하는 방법으로 단일 모델이 가지는 예측력 부족이나 과적합 위험을 극복하는 데 의의가 있음.

대표적으로 Bagging, Boosting, Stacking 사용함.

78. Bagging
배깅은 Bootstrap Ensemble의 준말로, 학습 데이터셋을 여러 개의 서브셋으로 분할하고 각 서브셋을 여러 개의 모델에 각각 학습시키는 것.

여러 개의 Decision Tree를 Bagging으로 결합한 Random Forest가 대표적임.

79. Boosting
여러 개의 모델을 사용하되, 이전에 학습시킨 모델의 단점에 더욱 집중하여 다음 학습에서 개선하는 방향으로 학습하는 순차적 학습 기법.
AdaBoost가 대표적임.

80. Stacking
서로 다른 모델을 개별 학습시키고, 각 모델의 예측을 Meta Model이 조합하여 최종 예측을 수행하는 기법.

81. Natural Language Processing
자연어 처리는 문자 데이터를 저차원의 숫자 벡터로 변환하여 컴퓨터가 그 의미와 관계를 이해할 수 있게 하고 이를 통해 새로운 문장을 생성하거나 번역에 이용하는 인공지능의 한 분야임.

82. Word2Vec
문자 데이터를 저차원 숫자 벡터로 변환하여 컴퓨터가 의미와 관계를 이해할 수 있게 하는 Word Embedding 방법 중 하나임.

관계있는 단어끼리는 가깝게, 관계없는 단어끼리는 멀리하도록 학습하는 것이 핵심이다.

83. Skip-Gram
중심 단어를 사용하여 주변 단어들을 예측하는 기법으로, 일반적인 단어보다 희귀한 단어들을 예측하는 데 특화됨.

84. Continuous Bag Of Words
CBOW는 주변 단어들을 활용하여 중심 단어가 무엇인지 예측하는 기법으로, 희귀한 단어보다 일반적인 단어들을 예측하는 데 특화됨.

85. Tokenization
토큰화는 문장을 작은 단위인 Token으로 분리하는 작업임.

ex) 저는 지원자 송현교입니다
=> '저는', '지원자', '송현교', '입니다'

86. Stemming
어간 추출은 품사에서 단순히 접미사를 잘라냄으로써 단어의 기본형을 알아내는 방법임.

ex) Learned, Learning
=> Learn, Learn

그러나 Studied, Studies는 Studi가 되어 버리는 등 낮은 정확도 보임. 대신 빠르다.

87. Lemmatization
표제어 추출은 문장 내에서 품사가 어떤 의미로 쓰였는지까지 분석하여 정확한 기본형을 알아내는 방법. Stemming에 비해 상대적으로 느리지만 정확하다.

ex) Studied, Studied
=> Study, Study

88. Morphological Analysis
형태소 분석이라 하며, 문장을 아주 작은 Token인 형태소 단위로 분리하는 것을 의미함.

ex) 저는 지원자 송현교입니다.
=> '저', '는', '지원', '자', '송현교', '입니다'

89. Representation Learning
데이터를 저차원 숫자 벡터로 표현하고 벡터 내 유의미한 패턴을 추출 및 학습하는 방법

90. Seq2Seq
시퀀스 투 시퀀스 모델은 입력 시퀀스를 압축하고, 해제하며 자연어 처리하는 모델.

인코더와 디코더로 구성되어, 인코더가 문장을 매우 작은 벡터로 압축하고, 디코더가 압축 해제하며 새로운 문장을 생성하거나 번역에 이용한다.

91. Topic Modeling
인공지능이 문서 내 단어의 등장 빈도, 관계를 파악함으로써 문서의 주제를 알아내는 것.

92. Transformer
'Attention is all you need' 논문에서 제안된 NLP 모델로, Attention Mechanism이 도입되었음. 기존 RNN의 소실되는 데이터에 Attention이 적용되는 문제가 있었고, 극복을 위해 제안된 Self-Attention Mechanism은 현재 Transformer 모델에서 필수적임.

93. Bidirectional Encoder Representation from Transformers
BERT는 구글에서 제작한 NLP 모델이다.
기존의 NLP 모델들이 왼쪽에서 오른쪽으로 데이터를 처리해 나가는 순방향 구조였던 것과 달리 BERT는 양방향으로 데이터를 처리해 나가며 높은 이해도와 훨씬 부드러운 문장 구조를 생성하는 것이 특징.

94. Confusion Matrix
혼동 행렬은 분류 모델의 성능을 평가하는 지표 4가지를 2*2 행렬로 표현한 것임.

TP, TN, FP, FN으로 구성.

TP : True Positive, 양성 데이터를 모델이 양성이라 올바르게 예측한 경우.
TN : True Negative, 음성 데이터를 모델이 음성이라 올바르게 예측한 경우.
FP(Type 1 Error) : False Positive, 음성 데이터를 모델이 양성이라 잘못 예측한 경우.
FN(Type 2 Error) : False Negative, 양성 데이터를 모델이 음성이라 잘못 예측한 경우.

이 4가지 지표를 통해 Accuracy, Sensitivity, Recall, Precision, F1 Score 구할 수 있음.

가장 많이 사용되는 Recall과 Precision, F1 Score의 계산식은 다음과 같다.

Recall(재현율) : TP / TP+FN
실제 양성 데이터를 모델이 양성이라 올바르게 예측한 '비율'을 의미함.

Precision(정밀도) : TP / TP+FP
모델이 양성이라 판단한 것 중 실제 양성 데이터의 비율

F1 Score : 2 * (Precision*Recall / Precision+Recall)
재현율과 정밀도의 조화평균으로, 둘 사이에 얼마만큼의 관계가 있는지를 나타냄.

95. Reciever Operating Characteristic Curve
ROC Curve는 분류 모델의 성능을 평가하기 위한 지표로, x축을 FP Rate, y축을 TP Rate로 하여 다양한 Threshold에 대한 그래프를 그린 것임.

좋은 분류 모델은 FPR이 낮고 TPR이 높아야 하므로 그래프가 좌측 상단에 수렴할수록 좋은 모델임.

96. Area Under the Curve
ROC Curve의 하단 면적으로, 분류 모델의 성능을 평가하는 지표임.

0~1까지의 값으로 나타나며 1은 완벽한 분류, 0.5는 랜덤한 분류, 0.5 이하는 잘못된 분류를 의미.

97. Recommender System
추천 시스템은 Collaborative Filtering 기반으로, User가 관심 가질만한 Item을 추천하는 기술을 의미함.

98. Collaborative Filtering
유사한 취향, 취미를 가진 사용자들은 같은 Item을 좋아할 것이다 라는 이치를 기반으로 필터링 시스템을 구현한 것.

99. (Batch) Gradient Descent
손실함수의 값이 최적해에 도달하는 것을 목표로 한 최적화 알고리즘. 손실함수가 다변수함수라 가정하였을 때 각 변수에 대해 Paramete로 편미분을 수행하면 가장 가파른 방향을 가리키는 Gradient가 도출되는데, 그 방향의 반대 방향으로 나아가면 최적해에 도달할 수 있다는 원리를 기반으로 구현됨. 한 번에 얼마나 나아갈지는 Learning Rate로 결정해줄수 있음.

Batch Gradient Descent의 경우 모든 데이터 포인트의 Gradient를 구한 뒤 한 번에 업데이트를 진행하기 때문에 연산량이 많고 시간이 오래 걸림. 해결하기 위한 Optimizer로 SGD, Mini-Batch GD, Momentum, NAG, Adagrad, RmsProp, Adam 제안됨.

100. Stochastic Gradient Descent
확률적 경사 하강법은 Batch GD의 단점을 보완한 알고리즘으로, 하나의 데이터 포인트에 대한 Gradient만 구한 뒤 업데이트하는 것을 반복함. 매우 빠른 속도, 노이즈 학습의 위험 약간 있음.

101. Mini-Batch Gradient Descent
미니배치 경사 하강법은 Batch GD와 SGD의 절충안으로, 각 미니배치 내 Gradient를 구하고 업데이트하는 것을 반복함. 빠르고, SGD보다 안정적으로 수렴함.

102. Momentum
이전 가중치 업데이트량을 다음 가중치 업데이트에 반영함으로써 가속도를 더해 빠르게 수렴함.

103. Nesterov Accelerated Gradient
Momentum 기반으로, 가중치 업데이트 방향을 예측하고, 예측 위치에서 기울기를 계산함. Momentum보다 빠름.

104. Adagrad
자주 등장하는 파라미터는 작은 학습률로, 드물게 등장하는 파라미터는 높은 학습률로 조정함.

105. RmsProp
Exponential Weighted Moving Average(지수 가중 이동 평균)을 사용하여 최근의 기울기에는 높은 학습률을 적용하고, 과거의 기울기는 점차 잊어버림.

106. Adam
기울기에 대한 1차 Moment(평균)과 2차 Moment(분산)을 동시에 추적하여 가중치 업데이트.

107. Density Estimation
밀도 추정은 확률밀도함수를 구하기 위해 분포 내에서 어떤 요소가 어디에 얼마나 존재하는지 분석하는 것을 의미함.

모수적 측정과 비모수적 측정 방식으로 구분되며, 모수적 측정은 주로 Gaussian Distribution, 비모수적 측정은 주로 히스토그램을 사용.

108. Feedback Loop
최종 출력이 다시 입력 레이어로 돌아가는 순환적 구조.

109. Depthwise Separable Convolution
기존의 Convolution이 RGB 3채널을 한 번에 묶어 필터 슬라이딩하던 것과 다르게 각 채널을 따로 처리한 뒤 결합하는 방식의 합성곱 연산. 효율적인 연산 방식이므로 경량 네트워크인 MobileNet과 EfficientNet에서 사용되기도 했으며, 필자가 캡스톤디자인 프로젝트에 사용한 YOLOv7 모델이 Depthwise Convolution 연산을 활용한 ConvNexT 기반임.

110. Depthwise Convolution
RGB 채널을 3개 채널로 분리하고, 각 채널에 따로따로 필터를 슬라이딩시켜 3개의 특징 맵을 생성함.

111. Pointwise Convolution
1*1 Convolution이라고도 하며, Depthwise Convolution을 통해 만들어진 특징 맵의 정보들을 결합함.

112. KL Divergence
쿨백 라이블러 발산은 두 확률분포간의 거리를 통해 정보의 손실량을 계산하는 방법임.

113. Central Limit Theorem
중심극한정리는 평균이 Mu, 분산이 Sigma^2인 어떤 모집단으로부터 랜덤한 샘플변수 Xi를 추출하고, Xi에 대한 표본평균을 구했을때 Xi가 Independent Identical Distribution을 만족한다면 Xi의 개수 N이 커질수록 표본평균의 분포가 Gaussian Distribution의 형태에 가까워지는 것을 의미함.

Xi가 어떤 분포를 따르더라도 i.i.d를 만족하기만 한다면 N이 충분히 클 때 무조건 Gaussian Distribution의 형태가 됨.

계산식 : 1/N Sigma(i=1~N) Xi

*****YOLOv7*****

YOLOv7은 필자가 캡스톤디자인 프로젝트에 이용한 모델로, CNN을 기반으로 하여 실시간 객체 탐지에 특화되었다.

이전에 높은 성능을 보이던 Mask R-CNN보다 550% 향상된 속도, 10% 향상된 정확도를 보였다는 연구 결과.

CNN의 특징인 공간 정보 추출과, Vision Transformer의 특징인 전역 정보 추출에서 핵심 개념을 뽑아 결합한 것이 핵심. 그 내용은 다음과 같다.

1) Extended Efficient Label Aggregation Network을 통해 이미지의 공간적 정보와 특징을 효율적으로 추출, 결합함.

2) Model Reparameterization
학습 중에는 여러 레이어로 복잡한 패턴을 추출, 학습하지만 학습 완료 시 여러 레이어들을 단일 레이어 몇 개로 합침으로써 파라미터를 줄이고 모델을 경량화시킴.

3) Dynamic Label Aggregation
다양한 크기의 Anchor Box를 생성해 두었다가, 감지된 객체의 특징에 맞는 Anchor Box를 꺼내 Intersection Over Union과 Non-Max Supression 연산하여 사용자에게 단일 바운딩 박스로 출력함.

4) Bag Of Freebies
'YOLOv7:Trainable Bag Of Freebies' 논문에서 제안된 기법으로, 모델이 제공받은 데이터에 자체적인 데이터 증강을 적용하여 사용자의 이미지 전처리 과정 없이도 스스로 일반화 능력을 향상시킴.

5) ConvNexT
CNN의 발전 형태임. 4가지 특징에 기반하여 효율적인 학습을 가능케 함.

5-1) Batch Normalization 대신 Layer Normalization
미니배치에 대한 입력 데이터가 아닌, 차원 단위로 표준화를 수행하여 Batch Normalization의 한계를 극복하고 성능을 향상시킴

Batch Normalization의 한계 : Batch Size에 매우 의존적임, 시퀀스 데이터 처리가 어려움.

5-2) ReLu 대신 Gaussian Error Linear Unit을 사용하여 음수 값을 부드럽게 처리함.

5-3) Depthwise Convolution
앞서 서술한 Depthwise Convolution과 동일.

5-4) ResNet의 Skip-Connection
잔차 연결을 도입하여 정보 손실이 일어나지 않도록 함.
